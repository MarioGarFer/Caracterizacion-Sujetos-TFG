{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33ed117",
   "metadata": {},
   "source": [
    "# Extracción de nuevas características\n",
    "Este script calcula nuevas métricas para cada sujeto a partir de los resultados de detección de FFT.\n",
    "Lee el archivo CSV con los resultados de detección y calcula las siguientes métricas:\n",
    "1. Tasa de detección\n",
    "2. Varianza en el porcentaje de detección a través de los ensayos\n",
    "3. Proporción de detección temprana (por debajo de 1.5s)\n",
    "4. Asimetría de la potencia\n",
    "5. Índice de robustez\n",
    "6. Entropía de la detección a través de frecuencias\n",
    "7. Respuestas fuertes (porcentaje > 66.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06672b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy, skew\n",
    "import os\n",
    "\n",
    "# === Cargar datos ===\n",
    "df = pd.read_csv(\"./results/fft_detection_results_combined.csv\")\n",
    "threshold = [1, 3, 5]\n",
    "\n",
    "# Para cada umbral, se generará un nuevo archivo CSV con las métricas\n",
    "for t in threshold:\n",
    "    suffix = f\"_{t}dB\"\n",
    "\n",
    "    # === Inicializar lista para almacenar las nuevas features por sujeto ===\n",
    "    enhanced_metrics = []\n",
    "\n",
    "    # === Agrupar por sujeto ===\n",
    "    subjects = df[\"Subject\"].unique()\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_data = df[df[\"Subject\"] == subject]\n",
    "\n",
    "        # Variables base\n",
    "        signal_detected = subject_data[\"SignalDetected\"].sum()\n",
    "        avg_power = subject_data[\"AvgPower\"].mean()\n",
    "        power_variability = subject_data[\"PowerVariability\"].mean()\n",
    "        detected_time_pct = subject_data[f\"DetectedTimePercentage{suffix}\"].mean()\n",
    "        detection_time = subject_data[f\"DetectionTime{suffix}\"].mean()\n",
    "\n",
    "        # Feature 1: Detection Rate\n",
    "        total_trials = subject_data[\"Trial\"].nunique()\n",
    "        detection_rate = signal_detected / (total_trials * subject_data[\"Freq\"].nunique())\n",
    "\n",
    "        # Feature 2: Variance in detection percentage across trials\n",
    "        trial_detection_pct = subject_data.groupby(\"Trial\")[f\"DetectedTimePercentage{suffix}\"].mean()\n",
    "        detection_pct_var = trial_detection_pct.var()\n",
    "\n",
    "        # Feature 3: Early detection ratio (below 1.5s)\n",
    "        early_detection_ratio = (subject_data[f\"DetectionTime{suffix}\"] < 1.5).mean()\n",
    "\n",
    "        # Feature 4: Skewness of power\n",
    "        power_skew = skew(subject_data[\"AvgPower\"])\n",
    "\n",
    "        # Feature 5: Robustness Index\n",
    "        robustness_index = detected_time_pct * (1 / detection_time) if detection_time > 0 else 0\n",
    "\n",
    "        # Feature 6: Entropy of detection across frequencies\n",
    "        freq_detection = subject_data.groupby(\"Freq\")[\"SignalDetected\"].mean()\n",
    "        freq_entropy = entropy(freq_detection + 1e-9)  # small value to avoid log(0)\n",
    "\n",
    "        # Feature 7: Strong responses (percentage > 66.6%)\n",
    "        strong_responses = np.sum(subject_data[f\"DetectedTimePercentage{suffix}\"] > 66.6)\n",
    "\n",
    "        enhanced_metrics.append({\n",
    "            \"Subject\": subject,\n",
    "            \"SignalDetected\": signal_detected,\n",
    "            \"AvgPower\": avg_power,\n",
    "            \"PowerVariability\": power_variability,\n",
    "            \"DetectedTimePercentage\": detected_time_pct,\n",
    "            \"DetectionTime\": detection_time,\n",
    "            \"DetectionRate\": detection_rate,\n",
    "            \"DetectionPctVar\": detection_pct_var,\n",
    "            \"EarlyDetectionRatio\": early_detection_ratio,\n",
    "            \"PowerSkewness\": power_skew,\n",
    "            \"RobustnessIndex\": robustness_index,\n",
    "            \"FreqEntropy\": freq_entropy,\n",
    "            \"StrongResponses\": strong_responses\n",
    "        })\n",
    "\n",
    "    # Convertir a DataFrame y guardar\n",
    "    enhanced_df = pd.DataFrame(enhanced_metrics)\n",
    "    output_path = f\"./results/enhanced_subject_metrics{t}.csv\"\n",
    "    enhanced_df.to_csv(output_path, index=False)\n",
    "    output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b71e9",
   "metadata": {},
   "source": [
    "# Clusterización de sujetos\n",
    "Este script se encarga de cargar las métricas generadas por el script anterior y realizar la clasificación de los sujetos en función de su rendimiento en BCI e ITR.\n",
    "Utiliza KNN como modelo de clasificación y guarda los resultados en un archivo CSV para cada umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en: ./results/classification_results1.csv\n",
      "Resultados guardados en: ./results/classification_results3.csv\n",
      "Resultados guardados en: ./results/classification_results5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# === Configuración ===\n",
    "thresholds = [1, 3, 5]\n",
    "metrics_template = \"./results/enhanced_subject_metrics{thr}.csv\"\n",
    "rankings_file = \"./results/subject_bci_itr.csv\"\n",
    "output_template = \"./results/classification_results{thr}.csv\"\n",
    "\n",
    "# === Cargar etiquetas ===\n",
    "def get_ranking_labels(path, metric):\n",
    "\n",
    "    \"\"\"\n",
    "    Carga el archivo de rankings y asigna etiquetas a los sujetos\n",
    "    según su posición en el ranking de la métrica especificada.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    sorted_df = df.sort_values(by=metric, ascending=False).reset_index(drop=True)\n",
    "    labels = {}\n",
    "    n = len(df)\n",
    "    for i, row in sorted_df.iterrows():\n",
    "        if i < n / 3:\n",
    "            labels[int(row[\"Subject\"])] = 0  # Good\n",
    "        elif i < 2 * n / 3:\n",
    "            labels[int(row[\"Subject\"])] = 2  # Mid\n",
    "        else:\n",
    "            labels[int(row[\"Subject\"])] = 1  # Bad\n",
    "    return labels\n",
    "\n",
    "# === Ejecutar para cada threshold ===\n",
    "for thr in thresholds:\n",
    "    metrics_file = metrics_template.format(thr=thr)\n",
    "    output_csv = output_template.format(thr=thr)\n",
    "\n",
    "    # === Cargar métricas y etiquetas ===\n",
    "    df = pd.read_csv(metrics_file)\n",
    "    bci_labels = get_ranking_labels(rankings_file, \"BCI\")\n",
    "    itr_labels = get_ranking_labels(rankings_file, \"ITR\")\n",
    "\n",
    "    df[\"BCI_Class\"] = df[\"Subject\"].apply(lambda s: bci_labels.get(s, 2))\n",
    "    df[\"ITR_Class\"] = df[\"Subject\"].apply(lambda s: itr_labels.get(s, 2))\n",
    "\n",
    "    # === Definir métricas específicas del threshold actual ===\n",
    "    feature_columns = [\n",
    "        \"SignalDetected\", \"AvgPower\", \"PowerVariability\",\n",
    "        \"DetectedTimePercentage\", \"DetectionTime\",\n",
    "        \"DetectionRate\", \"DetectionPctVar\", \"EarlyDetectionRatio\",\n",
    "        \"PowerSkewness\", \"RobustnessIndex\", \"FreqEntropy\", \"StrongResponses\"\n",
    "    ]\n",
    "\n",
    "    # === Ejecutar combinaciones ===\n",
    "    all_results = []\n",
    "    for r in range(1, 13):  # combinaciones de 2 a 12\n",
    "        for combo in itertools.combinations(feature_columns, r):\n",
    "            X = df[list(combo)]\n",
    "            y_BCI = df[\"BCI_Class\"]\n",
    "            y_ITR = df[\"ITR_Class\"]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # === Dividir en conjuntos de entrenamiento y prueba ===\n",
    "            X_train_bci, X_test_bci, y_train_bci, y_test_bci = train_test_split(X_scaled, y_BCI, test_size=0.3, random_state=42)\n",
    "            X_train_itr, X_test_itr, y_train_itr, y_test_itr = train_test_split(X_scaled, y_ITR, test_size=0.3, random_state=42)\n",
    "\n",
    "            for model_name, model in [\n",
    "                (\"KNN\", KNeighborsClassifier(n_neighbors=3))\n",
    "            ]:\n",
    "                # === Para BCI ===\n",
    "                model.fit(X_train_bci, y_train_bci)\n",
    "                y_pred_bci = model.predict(X_test_bci)\n",
    "                acc_bci = accuracy_score(y_test_bci, y_pred_bci)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Threshold\": f\"{thr}dB\",\n",
    "                    \"Target\": \"BCI\",\n",
    "                    \"Model\": model_name,\n",
    "                    \"Metrics\": \" + \".join(combo),\n",
    "                    \"Accuracy\": acc_bci\n",
    "                })\n",
    "\n",
    "                # === Para ITR ===\n",
    "                model.fit(X_train_itr, y_train_itr)\n",
    "                y_pred_itr = model.predict(X_test_itr)\n",
    "                acc_itr = accuracy_score(y_test_itr, y_pred_itr)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Threshold\": f\"{thr}dB\",\n",
    "                    \"Target\": \"ITR\",\n",
    "                    \"Model\": model_name,\n",
    "                    \"Metrics\": \" + \".join(combo),\n",
    "                    \"Accuracy\": acc_itr\n",
    "                })\n",
    "\n",
    "    # === Guardar resultados ===\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Resultados guardados en: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b5e66",
   "metadata": {},
   "source": [
    "# Visualización de resultados\n",
    "Este script carga los resultados de clasificación y muestra las combinaciones más efectivas para cada umbral de detección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d1765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************\n",
      "Resultados para 1dB:\n",
      "Top combinaciones para ITR:\n",
      "                                                Metrics  Accuracy\n",
      "121                     DetectionRate + RobustnessIndex  0.666667\n",
      "41                     SignalDetected + RobustnessIndex  0.666667\n",
      "6687  SignalDetected + AvgPower + PowerVariability +...  0.619048\n",
      "1617  SignalDetected + AvgPower + PowerVariability +...  0.619048\n",
      "33                       SignalDetected + DetectionRate  0.619048\n",
      "3273  SignalDetected + AvgPower + PowerVariability +...  0.619048\n",
      "881   SignalDetected + DetectionRate + RobustnessInd...  0.619048\n",
      "1                                        SignalDetected  0.619048\n",
      "5067  SignalDetected + AvgPower + PowerVariability +...  0.619048\n",
      "11                                        DetectionRate  0.619048\n",
      "\n",
      "Top combinaciones para BCI:\n",
      "                                                Metrics  Accuracy\n",
      "1398  DetectedTimePercentage + DetectionRate + Power...  0.809524\n",
      "3308  SignalDetected + AvgPower + PowerVariability +...  0.809524\n",
      "6164  AvgPower + PowerVariability + DetectionRate + ...  0.809524\n",
      "806   SignalDetected + DetectedTimePercentage + Powe...  0.809524\n",
      "4286  AvgPower + PowerVariability + DetectionRate + ...  0.809524\n",
      "2100  SignalDetected + DetectedTimePercentage + Powe...  0.809524\n",
      "5252  SignalDetected + AvgPower + PowerVariability +...  0.809524\n",
      "3022  DetectedTimePercentage + DetectionRate + Power...  0.809524\n",
      "1308  PowerVariability + DetectionPctVar + Robustnes...  0.761905\n",
      "5210  SignalDetected + AvgPower + PowerVariability +...  0.761905\n",
      "\n",
      "********************\n",
      "Resultados para 3dB:\n",
      "Top combinaciones para ITR:\n",
      "                                                Metrics  Accuracy\n",
      "3781  SignalDetected + PowerVariability + DetectionR...  0.619048\n",
      "11                                        DetectionRate  0.619048\n",
      "1927  SignalDetected + PowerVariability + DetectionR...  0.619048\n",
      "1                                        SignalDetected  0.619048\n",
      "33                       SignalDetected + DetectionRate  0.619048\n",
      "3703  SignalDetected + PowerVariability + DetectionT...  0.571429\n",
      "7135  SignalDetected + PowerVariability + DetectionT...  0.571429\n",
      "2863  PowerVariability + DetectionRate + DetectionPc...  0.571429\n",
      "183   SignalDetected + PowerVariability + DetectionP...  0.571429\n",
      "261      SignalDetected + RobustnessIndex + FreqEntropy  0.571429\n",
      "\n",
      "Top combinaciones para BCI:\n",
      "                                                Metrics  Accuracy\n",
      "7704  SignalDetected + AvgPower + PowerVariability +...  0.761905\n",
      "242      SignalDetected + DetectionPctVar + FreqEntropy  0.761905\n",
      "6742  SignalDetected + AvgPower + PowerVariability +...  0.761905\n",
      "532       DetectionRate + DetectionPctVar + FreqEntropy  0.761905\n",
      "1530  DetectionRate + DetectionPctVar + RobustnessIn...  0.761905\n",
      "900   SignalDetected + DetectionPctVar + RobustnessI...  0.761905\n",
      "1048  AvgPower + DetectedTimePercentage + Robustness...  0.714286\n",
      "5132  SignalDetected + AvgPower + PowerVariability +...  0.714286\n",
      "296     AvgPower + DetectedTimePercentage + FreqEntropy  0.714286\n",
      "1158  AvgPower + PowerSkewness + RobustnessIndex + F...  0.714286\n",
      "\n",
      "********************\n",
      "Resultados para 5dB:\n",
      "Top combinaciones para ITR:\n",
      "                                                Metrics  Accuracy\n",
      "1                                        SignalDetected  0.619048\n",
      "11                                        DetectionRate  0.619048\n",
      "33                       SignalDetected + DetectionRate  0.619048\n",
      "4001  SignalDetected + DetectionTime + DetectionRate...  0.619048\n",
      "3849  SignalDetected + DetectedTimePercentage + Dete...  0.619048\n",
      "5789  SignalDetected + DetectedTimePercentage + Dete...  0.619048\n",
      "7203  SignalDetected + DetectedTimePercentage + Dete...  0.619048\n",
      "5905  SignalDetected + DetectionTime + DetectionRate...  0.619048\n",
      "7713  SignalDetected + AvgPower + PowerVariability +...  0.571429\n",
      "803   SignalDetected + DetectedTimePercentage + Powe...  0.571429\n",
      "\n",
      "Top combinaciones para BCI:\n",
      "                                                Metrics  Accuracy\n",
      "3420  SignalDetected + AvgPower + DetectedTimePercen...  0.761905\n",
      "2188  SignalDetected + DetectionRate + DetectionPctV...  0.761905\n",
      "4066  SignalDetected + DetectionRate + DetectionPctV...  0.761905\n",
      "6276  AvgPower + DetectedTimePercentage + DetectionR...  0.761905\n",
      "4426  AvgPower + DetectedTimePercentage + DetectionR...  0.761905\n",
      "5350  SignalDetected + AvgPower + DetectedTimePercen...  0.761905\n",
      "5392  SignalDetected + AvgPower + DetectedTimePercen...  0.761905\n",
      "6936  SignalDetected + AvgPower + DetectedTimePercen...  0.761905\n",
      "1900  SignalDetected + PowerVariability + DetectionT...  0.714286\n",
      "3968  SignalDetected + DetectedTimePercentage + Dete...  0.714286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Para cada umbral, cargar el CSV y mostrar los resultados\n",
    "for thr in [1, 3, 5]:\n",
    "    # Cargar CSV\n",
    "    df = pd.read_csv(f\"./results/classification_results{thr}.csv\")\n",
    "    print(\"\\n\" + \"*\" * 20)\n",
    "    print(f\"Resultados para {thr}dB:\")\n",
    "\n",
    "    # Ver las 10 combinaciones más efectivas para ITR\n",
    "    top_itr = df[df[\"Target\"] == \"ITR\"].sort_values(by=\"Accuracy\", ascending=False).head(10)\n",
    "    print(\"Top combinaciones para ITR:\")\n",
    "    print(top_itr[[\"Metrics\", \"Accuracy\"] + [col for col in top_itr.columns if col.startswith(\"Imp_\")]])\n",
    "\n",
    "    # Ver las 10 combinaciones más efectivas para BCI\n",
    "    top_bci = df[df[\"Target\"] == \"BCI\"].sort_values(by=\"Accuracy\", ascending=False).head(10)\n",
    "    print(\"\\nTop combinaciones para BCI:\")\n",
    "    print(top_bci[[\"Metrics\", \"Accuracy\"] + [col for col in top_bci.columns if col.startswith(\"Imp_\")]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d7530",
   "metadata": {},
   "source": [
    "A partir de estos resultados podemos estudiar que combinaciones de características dan los mejores resultados de agrupamiento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
